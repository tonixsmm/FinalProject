{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "Tony Nguyen\n",
    "\n",
    "CPSC 222 01\n",
    "\n",
    "Dr. Gina Sprint\n",
    "\n",
    "December 13th, 2022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "For our class final project, I choose to work primarily with my **Apple Health Sleep Data** and **Netflix Watching History**.\n",
    "\n",
    "Throughout this project, I want to learn more about my sleep history, specifically, how long would I sleep each night on average. I realize that it is instrumental to have a decent amount of sleep since we are all working in a high academic-demadning environment; thus, being able to sleep well is one of the easiest way to prevent ourselves from burning out.\n",
    "\n",
    "I am a big Netflix user. Watching series on Netflix is one of my ways to relax after school and work. Therefore, I want to know if there would be a correlation between the amount of serie episodes or movies I watched and the total time I got to sleep each night."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple Health Sleeping Dataset\n",
    "\n",
    "The original Apple Health Dataset takeout contains several tables in different formats including electrocardiogram in CSV, workout routes in GPX, health clinical reports in JSON and an XML that has every other data points that my phone and my watch collects. The file type I will be working with is XML.\n",
    "\n",
    "In this original XML file called `export.xml`, there are multiple entries for different type of health information, including the sleep data that I need. And since this XML file is too big, at approximately 390MB, it takes my computer a very long time to work with if I load it directly into a DataFrame. It is essentially unwsie since I will need to re-run this notebook multiple times during my coding process.\n",
    "\n",
    "Therefore, in the file `healthdata_preprocessing.py`, I load the original XML file into a DataFrame, then export it to a CSV file called `export_converted.csv`. Although the exported CSV size is still relatively big at roughly 260MB, the time it takes to run is significantly faster.\n",
    "\n",
    "The attributes of this dataset is as follow:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction: Briefly describe the project domain, the dataset, your hypotheses, and the classification task you implemented. More specifically:\n",
    "* Why is the domain important to you and why you are researching in this domain\n",
    "* What is the dataset format (e.g. CSV files, JSON files, a mix of the two, etc.)\n",
    "* What tables (emphasis on the plural here) are included in the dataset\n",
    "* How is the data in each table collected\n",
    "* How many instances are there in each table\n",
    "* Include a brief description of the attributes\n",
    "* What are you trying to classify in the dataset\n",
    "* What are potential impacts of the results\n",
    "* Who are stakeholders interested in your results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ccfa51b6a2c575f9ec4b5f633399d96d9a08ae2d3de4a2b338c15ea2dbb5975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
